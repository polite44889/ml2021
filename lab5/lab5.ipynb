{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторна робота 5\n",
    "### Студента групи МІТ-31\n",
    "### Ярощука Назара Юрійовича\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mplt\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import mae, mse\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "from sklearn import metrics, datasets, model_selection\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0  1.000000  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246  303.000000    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884  323.000000    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pd.read_csv('./water_potability.csv')\n",
    "\n",
    "model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 0\n",
       "Hardness           0\n",
       "Solids             0\n",
       "Chloramines        0\n",
       "Sulfate            0\n",
       "Conductivity       0\n",
       "Organic_carbon     0\n",
       "Trihalomethanes    0\n",
       "Turbidity          0\n",
       "Potability         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0  1.000000  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246  303.000000    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884  323.000000    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance=pd.get_dummies(model)\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ph    Hardness  Chloramines     Sulfate  Conductivity  \\\n",
      "0  1.000000  204.890455     7.300212  368.516441    564.308654   \n",
      "1  3.716080  129.422921     6.635246  303.000000    592.885359   \n",
      "2  8.099124  224.236259     9.275884  323.000000    418.606213   \n",
      "3  8.316766  214.373394     8.059332  356.886136    363.266516   \n",
      "4  9.092223  181.101509     6.546600  310.135738    398.410813   \n",
      "\n",
      "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
      "0       10.379783        86.990970   2.963135           0  \n",
      "1       15.180013        56.329076   4.500656           0  \n",
      "2       16.868637        66.420093   3.055934           0  \n",
      "3       18.436524       100.341674   4.628771           0  \n",
      "4       11.558279        31.997993   4.075075           0  \n",
      "0    20791.318981\n",
      "1    18630.057858\n",
      "2    19909.541732\n",
      "3    22018.417441\n",
      "4    17978.986339\n",
      "Name: Solids, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = insurance.drop(\"Solids\", axis=1)\n",
    "y = insurance[\"Solids\"]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "\n",
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)\n",
    "y_test = np.asarray(y_test).astype(np.float32)\n",
    "\n",
    "tf.random.set_seed=13\n",
    "\n",
    "model = tf.keras.Sequential([ \n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(), metrics=['mse'])\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 594833856.0000 - mse: 594833856.0000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 594399552.0000 - mse: 594399552.0000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 593965824.0000 - mse: 593965824.0000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 593540480.0000 - mse: 593540480.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 593110912.0000 - mse: 593110912.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 592681600.0000 - mse: 592681600.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 592259840.0000 - mse: 592259840.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 591839808.0000 - mse: 591839808.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 591416704.0000 - mse: 591416704.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 591001728.0000 - mse: 591001728.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 590581120.0000 - mse: 590581120.0000\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 590164864.0000 - mse: 590164864.0000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 589751744.0000 - mse: 589751744.0000\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 589335616.0000 - mse: 589335616.0000\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 588915008.0000 - mse: 588915008.0000\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 588496576.0000 - mse: 588496576.0000\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 588085440.0000 - mse: 588085440.0000\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 587664832.0000 - mse: 587664832.0000\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 587246336.0000 - mse: 587246336.0000\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 586830528.0000 - mse: 586830528.0000\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 586412736.0000 - mse: 586412736.0000\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 585992064.0000 - mse: 585992064.0000\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 585577664.0000 - mse: 585577664.0000\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 585153920.0000 - mse: 585153920.0000\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 584721280.0000 - mse: 584721280.0000\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 584292352.0000 - mse: 584292352.0000\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 583851200.0000 - mse: 583851200.0000\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 583404992.0000 - mse: 583404992.0000\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 582951744.0000 - mse: 582951744.0000\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 582508992.0000 - mse: 582508992.0000\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 582036608.0000 - mse: 582036608.0000\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 581581056.0000 - mse: 581581056.0000\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 581119360.0000 - mse: 581119360.0000\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 580648128.0000 - mse: 580648128.0000\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 580173184.0000 - mse: 580173184.0000\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 579703360.0000 - mse: 579703360.0000\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 579220928.0000 - mse: 579220928.0000\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 578738496.0000 - mse: 578738496.0000\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 578239744.0000 - mse: 578239744.0000\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 577746688.0000 - mse: 577746688.0000\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 577245248.0000 - mse: 577245248.0000\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 576734784.0000 - mse: 576734784.0000\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 576226560.0000 - mse: 576226560.0000\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 575713920.0000 - mse: 575713920.0000\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 575187712.0000 - mse: 575187712.0000\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 574680000.0000 - mse: 574680000.0000\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 574149184.0000 - mse: 574149184.0000\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 573621824.0000 - mse: 573621824.0000\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 573088896.0000 - mse: 573088896.0000\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 572548352.0000 - mse: 572548352.0000\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 572009472.0000 - mse: 572009472.0000\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 571454016.0000 - mse: 571454016.0000\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 570900736.0000 - mse: 570900736.0000\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 570333696.0000 - mse: 570333696.0000\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 569765440.0000 - mse: 569765440.0000\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 569188608.0000 - mse: 569188608.0000\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 568597248.0000 - mse: 568597248.0000\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 568011648.0000 - mse: 568011648.0000\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 567404288.0000 - mse: 567404288.0000\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 566805120.0000 - mse: 566805120.0000\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 566194240.0000 - mse: 566194240.0000\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 565580288.0000 - mse: 565580288.0000\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 564970304.0000 - mse: 564970304.0000\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 564352768.0000 - mse: 564352768.0000\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 563728128.0000 - mse: 563728128.0000\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 563087168.0000 - mse: 563087168.0000\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 562456384.0000 - mse: 562456384.0000\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 561797888.0000 - mse: 561797888.0000\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 561137920.0000 - mse: 561137920.0000\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 560464960.0000 - mse: 560464960.0000\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 559799040.0000 - mse: 559799040.0000\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 559107008.0000 - mse: 559107008.0000\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 558418368.0000 - mse: 558418368.0000\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 557714176.0000 - mse: 557714176.0000\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 557018240.0000 - mse: 557018240.0000\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 556311296.0000 - mse: 556311296.0000\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 555593664.0000 - mse: 555593664.0000\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 554864896.0000 - mse: 554864896.0000\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 554136256.0000 - mse: 554136256.0000\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 553404160.0000 - mse: 553404160.0000\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 552650112.0000 - mse: 552650112.0000\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 551911488.0000 - mse: 551911488.0000\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 551163968.0000 - mse: 551163968.0000\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 550416832.0000 - mse: 550416832.0000\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 549653760.0000 - mse: 549653760.0000\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 548880640.0000 - mse: 548880640.0000\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 548100224.0000 - mse: 548100224.0000\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 547312128.0000 - mse: 547312128.0000\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 546530816.0000 - mse: 546530816.0000\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 545732032.0000 - mse: 545732032.0000\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 544954240.0000 - mse: 544954240.0000\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 544161664.0000 - mse: 544161664.0000\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 543358976.0000 - mse: 543358976.0000\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 542553792.0000 - mse: 542553792.0000\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 541725248.0000 - mse: 541725248.0000\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 540889472.0000 - mse: 540889472.0000\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 540054912.0000 - mse: 540054912.0000\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 539179136.0000 - mse: 539179136.0000\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 538331328.0000 - mse: 538331328.0000\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 537440896.0000 - mse: 537440896.0000\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 536565920.0000 - mse: 536565920.0000\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 535679776.0000 - mse: 535679776.0000\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 534783936.0000 - mse: 534783936.0000\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 533885504.0000 - mse: 533885504.0000\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 532976512.0000 - mse: 532976512.0000\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 532059808.0000 - mse: 532059808.0000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 531139648.0000 - mse: 531139648.0000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 530224416.0000 - mse: 530224416.0000\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 529272384.0000 - mse: 529272384.0000\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 528362720.0000 - mse: 528362720.0000\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 527395968.0000 - mse: 527395968.0000\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 526457568.0000 - mse: 526457568.0000\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 525495424.0000 - mse: 525495424.0000\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 524532512.0000 - mse: 524532512.0000\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 523558016.0000 - mse: 523558016.0000\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 522591232.0000 - mse: 522591232.0000\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 521622304.0000 - mse: 521622304.0000\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 520649792.0000 - mse: 520649792.0000\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 519673216.0000 - mse: 519673216.0000\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 518710848.0000 - mse: 518710848.0000\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 517713792.0000 - mse: 517713792.0000\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 516717408.0000 - mse: 516717408.0000\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 515704544.0000 - mse: 515704544.0000\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 514688736.0000 - mse: 514688736.0000\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 513646144.0000 - mse: 513646144.0000\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 512621216.0000 - mse: 512621216.0000\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 511580672.0000 - mse: 511580672.0000\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 510556960.0000 - mse: 510556960.0000\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 509505696.0000 - mse: 509505696.0000\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 508462816.0000 - mse: 508462816.0000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 507439168.0000 - mse: 507439168.0000\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 506392640.0000 - mse: 506392640.0000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 505370976.0000 - mse: 505370976.0000\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 504312256.0000 - mse: 504312256.0000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 503262560.0000 - mse: 503262560.0000\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 502189408.0000 - mse: 502189408.0000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 501099392.0000 - mse: 501099392.0000\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 499998944.0000 - mse: 499998944.0000\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 498878240.0000 - mse: 498878240.0000\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 497762528.0000 - mse: 497762528.0000\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 496620384.0000 - mse: 496620384.0000\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 495510016.0000 - mse: 495510016.0000\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 494357344.0000 - mse: 494357344.0000\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 493222240.0000 - mse: 493222240.0000\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 492082336.0000 - mse: 492082336.0000\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 490914752.0000 - mse: 490914752.0000\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 489792000.0000 - mse: 489792000.0000\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 488615040.0000 - mse: 488615040.0000\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 487484480.0000 - mse: 487484480.0000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 486334976.0000 - mse: 486334976.0000\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 485188480.0000 - mse: 485188480.0000\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 484066368.0000 - mse: 484066368.0000\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 482910080.0000 - mse: 482910080.0000\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 481770880.0000 - mse: 481770880.0000\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 480619232.0000 - mse: 480619232.0000\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 479437888.0000 - mse: 479437888.0000\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 478233952.0000 - mse: 478233952.0000\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 477057920.0000 - mse: 477057920.0000\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 475826848.0000 - mse: 475826848.0000\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 474621280.0000 - mse: 474621280.0000\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 473387264.0000 - mse: 473387264.0000\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 472159424.0000 - mse: 472159424.0000\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 470952320.0000 - mse: 470952320.0000\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 469699840.0000 - mse: 469699840.0000\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 468483136.0000 - mse: 468483136.0000\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 467269216.0000 - mse: 467269216.0000\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 466010752.0000 - mse: 466010752.0000\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 464777184.0000 - mse: 464777184.0000\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 463511328.0000 - mse: 463511328.0000\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 462271552.0000 - mse: 462271552.0000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 460959744.0000 - mse: 460959744.0000\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 459695488.0000 - mse: 459695488.0000\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 458415488.0000 - mse: 458415488.0000\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 457102176.0000 - mse: 457102176.0000\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 455803008.0000 - mse: 455803008.0000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 454474368.0000 - mse: 454474368.0000\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 453147200.0000 - mse: 453147200.0000\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 451780864.0000 - mse: 451780864.0000\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 450480224.0000 - mse: 450480224.0000\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 449147296.0000 - mse: 449147296.0000\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 447809760.0000 - mse: 447809760.0000\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 446486400.0000 - mse: 446486400.0000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 445190176.0000 - mse: 445190176.0000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 443864512.0000 - mse: 443864512.0000\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 442555776.0000 - mse: 442555776.0000\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 441244288.0000 - mse: 441244288.0000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 439936160.0000 - mse: 439936160.0000\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 438621536.0000 - mse: 438621536.0000\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 437345536.0000 - mse: 437345536.0000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 436021440.0000 - mse: 436021440.0000\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 434749984.0000 - mse: 434749984.0000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 433449536.0000 - mse: 433449536.0000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 432162656.0000 - mse: 432162656.0000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 430829792.0000 - mse: 430829792.0000\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 429557344.0000 - mse: 429557344.0000\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 428186304.0000 - mse: 428186304.0000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 426830880.0000 - mse: 426830880.0000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 425488288.0000 - mse: 425488288.0000\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 424107168.0000 - mse: 424107168.0000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 422754368.0000 - mse: 422754368.0000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 421371424.0000 - mse: 421371424.0000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 419994240.0000 - mse: 419994240.0000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 418643584.0000 - mse: 418643584.0000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 417309056.0000 - mse: 417309056.0000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 415931744.0000 - mse: 415931744.0000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 414610496.0000 - mse: 414610496.0000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 413250624.0000 - mse: 413250624.0000\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 411897344.0000 - mse: 411897344.0000\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 410507968.0000 - mse: 410507968.0000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 409095296.0000 - mse: 409095296.0000\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 212325584.0000 - mse: 212325584.0000\n"
     ]
    }
   ],
   "source": [
    "history_2 = model.fit(X_train, y_train, epochs=200)\n",
    "\n",
    "score_1 = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000246AAA761F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "y1: 49112.69921875\n",
      "y2: 49112.69921875\n",
      "y1 - y2: 0.0\n"
     ]
    }
   ],
   "source": [
    "path = 'model.h5'\n",
    "\n",
    "model.save(path)\n",
    "\n",
    "loaded_model= tf.keras.models.load_model(path)\n",
    "\n",
    "y1 = model.predict(X_test)\n",
    "y2 = loaded_model.predict(X_test)\n",
    "print(f'y1: {y1.sum()}')\n",
    "print(f'y2: {y2.sum()}')\n",
    "print(f'y1 - y2: {(y1 - y2).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "transformer = make_column_transformer(\n",
    "    (MinMaxScaler(),[\"Chloramines\", \"Sulfate\", \"Conductivity\", \"Organic_carbon\", \"Trihalomethanes\"]), \n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"),['Turbidity','Potability'])\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "transformer.fit(X_train)\n",
    "\n",
    "X_train_norm = transformer.transform(X_train).astype(np.float32).toarray()\n",
    "print(type(X_train_norm))\n",
    "X_test_norm = transformer.transform(X_test).astype(np.float32).toarray()\n",
    "print(type(X_test_norm))\n",
    "\n",
    "model_2 = tf.keras.Sequential([ \n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step - loss: 646361984.0000 - mse: 646361984.0000 - mae: 23040.0742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36, 9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.compile(loss='mse', optimizer=Adam(), metrics=['mse', 'mae'])\n",
    "\n",
    "history_model_2 = model_2.fit(X_train_norm, y_train, validation_split=0.3, epochs=30, verbose=0)\n",
    "\n",
    "model_2.evaluate(X_test_norm, y_test)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_model_2.history['loss'])\n",
    "plt.plot(history_model_2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample:\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
      "    0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
      "   54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
      "  144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
      "  107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
      "  216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
      "  223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
      "  180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
      "  169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
      "  198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
      "  232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
      "  222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
      "  211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
      "  224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
      "  255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
      "  188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
      "  168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
      "  239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
      "  199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
      "  195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
      "  210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
      "  182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "Training label: 9\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "print(f\"Training sample:\\n{train_data[0]}\\n\") \n",
    "print(f\"Training label: {train_labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape, test_data.shape, test_labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28), ())"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape, train_labels[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x246a22fb7f0>,\n",
       " <keras.layers.core.dense.Dense at 0x246a22bee80>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.9634318 ],\n",
       "        [-0.5985635 ],\n",
       "        [-0.69924986],\n",
       "        [-1.1980811 ],\n",
       "        [-0.9001054 ],\n",
       "        [-0.6559883 ],\n",
       "        [-1.023167  ],\n",
       "        [ 0.9570822 ],\n",
       "        [-0.22494528],\n",
       "        [-0.7394023 ]], dtype=float32),\n",
       " (10, 1))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[1].get_weights()\n",
    "\n",
    "weights, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.40602487], dtype=float32), (1,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "biases, biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 10)                100       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8550c60217d6af2fd86eb867bc82f0bc173c8b38e1df221fbd1e5a6c992d1033"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
